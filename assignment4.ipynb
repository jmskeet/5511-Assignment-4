{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00fc08d",
   "metadata": {},
   "source": [
    "# Assignment 4 - NLP Disaster Tweets Kaggle Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a73e40",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This project is a binary text classification. The goal of this project is to develop a recurring nueral network model that can accurately identify Tweets whose content relates to a real disaster from those that do not. The data is provided by the Kaggle Natural Language Processing with Disaster Tweets Competition and located at https://www.kaggle.com/c/nlp-getting-started/overview.\n",
    "\n",
    "\n",
    "## Data Summary\n",
    "The data consists of training and test data.  The train.csv file contains the training data comprised of an id, keyword, location, Tweet text and ground truth labels. There are 7613 rows in the training data.  The test.csv file contains the test data comprised of an id, keyword, location, Tweet text, however it does not include a label. There are 3263 rows in the test data. The sample_submission.csv contains the ids of the test Tweets and sampleground truth labels. The labeles are to be replaced with test results and submitted for assessment of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5047e0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\john.stronks\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\john.stronks\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas emoji\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc401d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set Page Width to 100%\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6217c9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\john.stronks\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Load Required Resources\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caf7823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None \n",
      "\n",
      "Train Shape:  (7613, 5) \n",
      "\n",
      "   id keyword location                                               text\n",
      "0   0     NaN      NaN                 Just happened a terrible car crash\n",
      "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
      "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
      "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
      "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n",
      "None\n",
      "Test Shape:  (3263, 4) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import Data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv \")\n",
    "\n",
    "print(train_df.head(), '\\n')\n",
    "print(train_df.info(), '\\n')\n",
    "print('Train Shape: ', train_df.shape, '\\n')\n",
    "print(test_df.head(), '\\n')\n",
    "print(test_df.info())\n",
    "print('Test Shape: ', test_df.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec8a1a",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc73d6",
   "metadata": {},
   "source": [
    "EDA will be performed as follows:\n",
    "\n",
    "    1. Remove unnecessary columns (keyword and location)\n",
    "    2. Check for NaNs and Nulls in remaining columns\n",
    "    3. Understand distributions of data sets\n",
    "    4. Cleanse test strings\n",
    "        - Remove Punctuation\n",
    "        - Remove Stop Words\n",
    "        - Remove Hyperlinks\n",
    "        - Convert to all lower case\n",
    "    \n",
    "Columns keyword and location are irrelevent to the analysis and therefore removed from the data sets.\n",
    "\n",
    "**Drop keyword and location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5672811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text  target\n",
      "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
      "1   4             Forest fire near La Ronge Sask. Canada       1\n",
      "2   5  All residents asked to 'shelter in place' are ...       1\n",
      "3   6  13,000 people receive #wildfires evacuation or...       1\n",
      "4   7  Just got sent this photo from Ruby #Alaska as ...       1 \n",
      "\n",
      "   id                                               text\n",
      "0   0                 Just happened a terrible car crash\n",
      "1   2  Heard about #earthquake is different cities, s...\n",
      "2   3  there is a forest fire at spot pond, geese are...\n",
      "3   9           Apocalypse lighting. #Spokane #wildfires\n",
      "4  11      Typhoon Soudelor kills 28 in China and Taiwan\n"
     ]
    }
   ],
   "source": [
    "# drop key and location \n",
    "\n",
    "train_df = train_df.drop(['keyword', 'location'], axis=1)\n",
    "test_df = test_df.drop(['keyword', 'location'], axis=1)\n",
    "\n",
    "print(train_df.head(), '\\n')\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c1f3fb",
   "metadata": {},
   "source": [
    "**Check for Nulls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d0f5555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train id NaNs / Null Count:  0 \n",
      "\n",
      "Test id NaNs / Null Count:  0 \n",
      "\n",
      "Train text NaNs / Null Count:  0 \n",
      "\n",
      "Train text NaNs / Null Count:  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check for NaNs and Nulls\n",
    "print('Train id NaNs / Null Count: ', train_df['id'].isna().sum(), '\\n')\n",
    "print('Test id NaNs / Null Count: ', train_df['id'].isna().sum(), '\\n')\n",
    "print('Train text NaNs / Null Count: ', train_df['text'].isna().sum(), '\\n')\n",
    "print('Train text NaNs / Null Count: ', train_df['text'].isna().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90108e",
   "metadata": {},
   "source": [
    "**Label Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e469076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "242976c4",
   "metadata": {},
   "source": [
    "### Cleanse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ed0d9",
   "metadata": {},
   "source": [
    "**Remove Hyperlinks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d9b9575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "@bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C\n",
      "#3: Car Recorder ZeroEdgeå¨ Dual-lens Car Camera Vehicle Traffic/Driving History/Accident Camcorder  Large Re... http://t.co/kKFaSJv6Cj\n",
      "After\n",
      "@bbcmtd Wholesale Markets ablaze \n",
      "#3: Car Recorder ZeroEdgeå¨ Dual-lens Car Camera Vehicle Traffic/Driving History/Accident Camcorder  Large Re... \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print('Before')\n",
    "print(train_df['text'][31])\n",
    "print(test_df['text'][32])\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(lambda x:  re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "test_df['text'] = test_df['text'].apply(lambda x:  re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "\n",
    "print('After')\n",
    "print(train_df['text'][31])\n",
    "print(test_df['text'][32])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d56187",
   "metadata": {},
   "source": [
    "**Remove Punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33726680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text  target\n",
      "0   1  Our Deeds are the Reason of this earthquake Ma...       1\n",
      "1   4              Forest fire near La Ronge Sask Canada       1\n",
      "2   5  All residents asked to shelter in place are be...       1\n",
      "3   6  13000 people receive wildfires evacuation orde...       1\n",
      "4   7  Just got sent this photo from Ruby Alaska as s...       1 /n\n",
      "   id                                               text\n",
      "0   0                 Just happened a terrible car crash\n",
      "1   2  Heard about earthquake is different cities sta...\n",
      "2   3  there is a forest fire at spot pond geese are ...\n",
      "3   9              Apocalypse lighting Spokane wildfires\n",
      "4  11      Typhoon Soudelor kills 28 in China and Taiwan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John.Stronks\\AppData\\Local\\Temp\\1\\ipykernel_19404\\2543514056.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_df['text'] = train_df['text'].str.replace(r'[^\\w\\s]+', '')\n",
      "C:\\Users\\John.Stronks\\AppData\\Local\\Temp\\1\\ipykernel_19404\\2543514056.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_df['text'] = test_df['text'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "train_df['text'] = train_df['text'].str.replace(r'[^\\w\\s]+', '')\n",
    "test_df['text'] = test_df['text'].str.replace(r'[^\\w\\s]+', '')\n",
    "print(train_df.head(), '/n')\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72794fa",
   "metadata": {},
   "source": [
    "**Remove Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4eebf46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text  target\n",
      "0   1   Our Deeds Reason earthquake May ALLAH Forgive us       1\n",
      "1   4              Forest fire near La Ronge Sask Canada       1\n",
      "2   5  All residents asked shelter place notified off...       1\n",
      "3   6  13000 people receive wildfires evacuation orde...       1\n",
      "4   7  Just got sent photo Ruby Alaska smoke wildfire...       1 /n\n",
      "   id                                               text\n",
      "0   0                   Just happened terrible car crash\n",
      "1   2  Heard earthquake different cities stay safe ev...\n",
      "2   3  forest fire spot pond geese fleeing across str...\n",
      "3   9              Apocalypse lighting Spokane wildfires\n",
      "4  11             Typhoon Soudelor kills 28 China Taiwan\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "  \n",
    "stop_words = stopwords.words('english')\n",
    "train_df['text'] = train_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "print(train_df.head(), '/n')\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303fc557",
   "metadata": {},
   "source": [
    "**Convert to all lower case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cd69dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "bbcmtd Wholesale Markets ablaze\n",
      "3 Car Recorder ZeroEdgeå Duallens Car Camera Vehicle TrafficDriving HistoryAccident Camcorder Large Re\n",
      "After\n",
      "bbcmtd wholesale markets ablaze\n",
      "3 car recorder zeroedgeå duallens car camera vehicle trafficdriving historyaccident camcorder large re\n"
     ]
    }
   ],
   "source": [
    "print('Before')\n",
    "print(train_df['text'][31])\n",
    "print(test_df['text'][32])\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(lambda x:  x.lower())\n",
    "test_df['text'] = test_df['text'].apply(lambda x:  x.lower())\n",
    "\n",
    "print('After')\n",
    "print(train_df['text'][31])\n",
    "print(test_df['text'][32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b6cd68",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Remove Stop Words from Text in DataFrame Column, https://www.datasnips.com/58/remove-stop-words-from-text-in-dataframe-column/\n",
    "\n",
    "How to Remove URLs from Text in Python, https://bobbyhadz.com/blog/python-remove-url-from-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577d945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
